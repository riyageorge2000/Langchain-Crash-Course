{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "956ff3a4",
   "metadata": {},
   "source": [
    "# Chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from secret_key import openapi_key\n",
    "import os \n",
    "os.environ['OPENAI_API_KEY'] = openapi_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embd = OpenAIEmbeddings()\n",
    "vectordb = FAISS.load_local(\"docs/cs229_lecture1_faiss_index\",embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a409bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c58c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm.predict(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc11bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectordb.as_retriever())\n",
    "qa_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23700502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa = ConversationalRetrievalChain.from_llm(llm,retriever=vectordb.as_retriever(),memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did Professor Ng say about the class topics?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622478ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b280672",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did he say about the class prerequisites?\"\n",
    "qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b012fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_new_prompt = ConversationalRetrievalChain.from_llm(llm,retriever=vectordb.as_retriever(),memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56786d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did he say about the class prerequisites?\"\n",
    "qa_new_prompt({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e818e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
